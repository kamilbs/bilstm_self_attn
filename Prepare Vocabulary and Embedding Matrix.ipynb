{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from utils import preprocessing_helpers\n",
    "from utils.fasttext_cleaner import fasttext_cleaning\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/data_sentiment140' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(data_folder, 'train_data.csv')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fasttext_cleaning will perform a basic cleaning and tokenize by whitespace, we pass the result to split(' ') to get a list of token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_text'] = data['text'].apply(lambda x: fasttext_cleaning(x).split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small treatment for tweets, it separates the hashtag from the words , for example the token #jobs becomes two tokens #, jobs , we keep the # (since using an RNN model , might help ..but not sure if its better to keep it or remove it, so we'll just leave it for the moment.\n",
    "For @xxx, we'll replace with a special token TWEETER_USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_text'] = data['tokenized_text'].apply(preprocessing_helpers.small_cleaning_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64882          [<TWEETER_USER>, its, not, on, in, colorado]\n",
       "819782           [unhappy, about, my, lack, of, discipline]\n",
       "598282    [lost, a, follower, ,, was, it, something, i, ...\n",
       "441008    [played, the, fight, night, round, demo, just,...\n",
       "395274    [<TWEETER_USER>, wow, ,, i, ', ve, checked, th...\n",
       "Name: tokenized_text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokenized_text'].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(list_of_tokenized_texts, min_count=2):\n",
    "    \"\"\"Take a list of of tokenized text and create a vocabulary dict word->id\"\"\"\n",
    "    \n",
    "    df_counter = Counter([token for tokenized_text in list_of_tokenized_texts for token in set(tokenized_text)])\n",
    "    vocabulary_list = sorted(token for token,df_count in df_counter.items() if df_count>=min_count)\n",
    "    vocabulary_list = ['<PAD>'] + vocabulary_list\n",
    "    return vocabulary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_list = create_vocabulary(data['tokenized_text'].tolist(), min_count=5)\n",
    "with open(os.path.join(data_folder,'vocabulary_list.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(vocabulary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47874"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_list) # Maybe increase the min_count in the previous cell if vocabulary is very very big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=data['tokenized_text'].tolist(),size=embedding_size, window=5, min_count=0, workers=4)\n",
    "model.train(data['tokenized_text'].tolist(), total_examples=len(data), epochs=5)\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.8513270616531372),\n",
       " ('fab', 0.8434876203536987),\n",
       " ('fabulous', 0.841629147529602),\n",
       " ('brilliant', 0.8153545260429382),\n",
       " ('wonderful', 0.7884383201599121),\n",
       " ('terrific', 0.7380696535110474),\n",
       " ('lovely', 0.6846454739570618),\n",
       " ('awesome', 0.6787641048431396),\n",
       " ('amazing', 0.6767555475234985),\n",
       " ('incredible', 0.6757609248161316)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('fantastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('despise', 0.6307151913642883),\n",
       " ('dislike', 0.6078054308891296),\n",
       " ('hates', 0.5803361535072327),\n",
       " ('sucks', 0.5413668155670166),\n",
       " ('suck', 0.5285280346870422),\n",
       " ('hating', 0.5043717622756958),\n",
       " ('loathe', 0.4923359751701355),\n",
       " ('haaate', 0.4749675989151001),\n",
       " ('stupid', 0.47068506479263306),\n",
       " ('love', 0.4668755531311035)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sushi', 0.6935381889343262),\n",
       " ('pizza', 0.6706090569496155),\n",
       " ('snacks', 0.6616131663322449),\n",
       " ('meat', 0.630408763885498),\n",
       " ('subway', 0.6285064816474915),\n",
       " ('foods', 0.6203563213348389),\n",
       " ('ingredients', 0.616908073425293),\n",
       " ('pasta', 0.6168296933174133),\n",
       " ('muay', 0.6165291666984558),\n",
       " ('seafood', 0.614884614944458)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('food')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_token = {token_id: token for token_id, token in enumerate(vocabulary_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV = 1 # Number of uknown token buckets\n",
    "total_size = len(vocabulary_list) + NUM_OOV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.random.uniform(-0.5,0.5,size=(total_size, embedding_size))/embedding_size # Initialization of the embedding matrix\n",
    "emb_matrix[0] = np.zeros(embedding_size) # PAD token will get the id 0 and will be full of 0s\n",
    "for i in range(1, total_size-NUM_OOV): # Except pad token and OOV buckets\n",
    "    word = id_to_token[i]\n",
    "    emb_matrix[i] = word_vectors[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder,'embedding_matrix.npy'), 'wb') as f:\n",
    "    np.save(f, emb_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
